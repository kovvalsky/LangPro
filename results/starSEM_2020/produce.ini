
######################## Functions #####################
[]
prelude =
    import re

    def flag2par(flag):
        '''Interpret acronyms of parameters.
           cN - core number, rN - rule application number,
           pMN - patterns with M terms and N terms.
        '''
        # lookup table
        mapping = {'al': 'aall',
                   'ch': 'constchk',
                   'w3': 'wn_ant, wn_sim, wn_der',
                   '-k': 'no_kb',
                   '-w': 'no_wn',
                   # rN
                   # induction parameters
                   'ab': 'align-both',
                   'an': 'align-no_align',
                   'aa': 'align-align',
                   'ch': 'constchk',
                   'cKB': 'constKB',
                   'cT': 'compTerms'
                   # pNM
                  }
        if flag in mapping:
            return mapping[flag]
        # cores or rule limit
        m = re.match('[rcpv](\d+)$', flag)
        if m:
            n = int(m.group(1))
            if flag[0] == 'r':
                return "ral({})".format(n)
            # used for injecting version for file,
            # it has no affect for proving
            elif flag[0] == 'v':
                return "v{}".format(n)
            elif flag[0] == 'c':
                if n == 1:
                    return 'true'
                return "parallel({})".format(n if n else '_')
            else: # induction parameter
                return "patterns-({})".format(expand_patterns(str(n)))
        raise ValueError('Unknown flag: {}'.format(flag))

    def flags2pars(flags):
        return ', '.join([ flag2par(f) for f in flags.split(',') ])

    def expand_patterns(pat):
        mappings = {'1': '_',
                    '2': '_@_',
                    '3': '(_@_)@_, _@(_@_)',
                    '4': '_@(_@(_@_)), _@((_@_)@_), (_@_)@(_@_), ((_@_)@_)@_, (_@(_@_))@_'
                    }
        patterns = ','.join([ mappings[p] for p in pat ])
        return "[{}]".format(patterns)

    def get_part(p):
        d = {'T': 'train',
             'D': 'trial',
             'E': 'test_annotated'
            }
        if p in d:
            return d[p]
        else:
            return '_'.join([ d[c] for c in p ])


#########################################################
########################## ccg_sen ######################
#########################################################

### create prolog facts representing NLI problems
# [results/starSEM_2020/ccg_sen/SICK_%{split}_sen.pl]
# dep.data = SICK_dataset/SICK_%{split}.txt
# dep.script = python/nlidata2prolog.py
# recipe =
#     mkdir -p results/starSEM_2020/ccg_sen/
#     python3 %{script}  %{data}  %{target} --fmt sen.pl \
#     --corpus sick_semeval

### tokenize the raw sentences
[results/starSEM_2020/ccg_sen/SICK_%{split}.spl]
dep.data = SICK_dataset/SICK_%{split}.txt
dep.script = python/nlidata2prolog.py
recipe =
    mkdir -p results/starSEM_2020/ccg_sen/
    python3 %{script}  %{data}  %{target}  --fmt spl \
    --tokenize nltk  --corpus sick_semeval

### get lemmas for tokenized sentences with easyccg
[results/starSEM_2020/ccg_sen/SICK_%{split}.easy.lem]
dep.data = results/starSEM_2020/ccg_sen/SICK_%{split}.spl
dep.easyccg = parsers/easyccg/easyccg.jar
recipe =
    cat %{data} | java -cp %{easyccg} uk.ac.ed.easyccg.lemmatizer.MorphaStemmer > %{target}

### get pos tags and ne tags for tokenized sentences with C&C tools
[results/starSEM_2020/ccg_sen/SICK_%{split}.cc.pos.ner]
dep.data = results/starSEM_2020/ccg_sen/SICK_%{split}.spl
dep.bin = parsers/rebank_candc/rebank_dist/bin
dep.models = parsers/rebank_candc/models
recipe =
    cat %{data} | \
    ./%{bin}/pos --model %{models}/pos --ifmt "%%w \n" --ofmt "%%w|%%p \n" | \
    ./%{bin}/ner --model %{models}/ner --ifmt "%%w|%%p \n" --ofmt "%%w|%%p|%%n \n" > %{target}

#########################################################
################# Parsing with DepCCG ###################

### parsing sentences all together (surprisingly context of sentences matters)
[results/starSEM_2020/ccg_sen/SICK_%{split}.depccg.%{m}.json]
cond = %{ m in ('trihf') }
dep.model = parsers/models_depccg/tri_headfirst
dep.spl = results/starSEM_2020/ccg_sen/SICK_%{split}.spl
recipe =
    cat %{spl} | depccg_en -m %{model} -f json > %{target}

### parsing sentences one by one
[results/starSEM_2020/ccg_sen/SICK_%{split}.depccg.%{m}.sep.json]
cond = %{ m in ('trihf') }
dep.model = parsers/models_depccg/tri_headfirst
dep.spl = results/starSEM_2020/ccg_sen/SICK_%{split}.spl
dep.depccg = python/parse_with_depccg_en.py
recipe =
    # while read line; do echo $line | depccg_en -m %{model} -f json; done < %{spl} > %{target} 2> %{target}.log
    python3 %{depccg} %{model} %{spl} --output %{target} --one > %{target}.log 2>&1
    # parses sentences by feeding them one-by-one to parser
############################################################

### convert depccg json derivations into prolog derivations
# [results/starSEM_2020/ccg_sen/SICK_%{split}_depccg.%{m}.pl]
# dep.lemma = results/starSEM_2020/ccg_sen/SICK_%{split}.easy.lem
# dep.deriv = results/starSEM_2020/ccg_sen/SICK_%{split}.depccg.%{m}.json
# dep.pos_ner = results/starSEM_2020/ccg_sen/SICK_%{split}.cc.pos.ner
# recipe =
#     python3 python/depccg2prolog.py  %{deriv}  %{target}  --anno %{pos_ner} --lemma %{lemma}

# merge 2 parts
[results/starSEM_2020/ccg_sen/SICK_%{p1}_%{p2}_%{ext}]
cond = %{ (ext == 'sen.pl' or ext.startswith('depccg')) and p1 in ('train', 'trial', 'test_annotated') }
# create ccg_sen/*_sen.pl files
dep.p1 = results/starSEM_2020/ccg_sen/SICK_%{p1}_%{ext}
dep.p2 = results/starSEM_2020/ccg_sen/SICK_%{p2}_%{ext}
dep.script = python/merge_ccg_sen_pl.py
flag = %{ '--sen-pl' if ext.endswith('sen.pl') else '--ccg-pl' }
recipe =
    python3  python/merge_ccg_sen_pl.py  --output  %{target}  %{flag} %{p1} %{p2}


# create ccg_sen directort with necessary files inside
[results/starSEM_2020/ccg_sen]
# create ccg_sen/*_sen.pl files
dep.train_sen = %{target}/SICK_train_sen.pl
dep.trial_sen = %{target}/SICK_trial_sen.pl
dep.test_sen = %{target}/SICK_test_annotated_sen.pl
# parse sentneces to create ccg_sen/*_ccg.pl files
dep.train_ccg = %{target}/SICK_train_depccg.trihf.sep.pl
dep.trial_ccg = %{target}/SICK_trial_depccg.trihf.sep.pl
dep.test_ccg = %{target}/SICK_test_annotated_depccg.trihf.sep.pl

#########################################################
################# Evaluate on a split ###################
#########################################################

#[results/starSEM_2020/Evaluate/%{proving_flags}]
#type = task
#parsers = %{ ('ccg', 'eccg', 'depccg.trihf.sep') }
#deps = %{ 'results/starSEM_2020/Evaluate/{}/{}'.format(p, proving_flags) for p in parsers }

#[results/starSEM_2020/Evaluate/%{parser}/%{proving_flags}]
#type = task
#cond = %{ parser in ('ccg', 'eccg', 'reccg', 'occg') or 'depccg' in parser }
#deps = %{ 'results/starSEM_2020/Evaluate/{}/{}_{}.log'.format(parser, p, proving_flags) for p in 'TDE' }

[results/starSEM_2020/Evaluate/%{parser}/%{p}_%{proving_flags}.log]
cond = %{ parser in ('ccg', 'eccg', 'reccg', 'occg') or 'depccg' in parser }
# create ccg_sen/*_sen.pl files
ppars = %{ flags2pars(proving_flags) }
ccg_sen = %{ 'results/starSEM_2020/ccg_sen' if 'depccg' in parser else 'ccg_sen_d' }
part = %{ get_part(p) }
ans = %{ target[:-3] + 'ans' }
dep.sen = %{ccg_sen}/SICK_%{part}_sen.pl
dep.ccg = %{ccg_sen}/SICK_%{part}_%{parser}.pl
dep.wn = WNProlog/wn.pl
recipe =
    mkdir -p results/starSEM_2020/Evaluate/%{parser}
    ( time swipl -g "parList([allInt, waif('%{ans}'), %{ppars}]), entail_all" -t halt -f prolog/main.pl -l % {wn} %{sen} %{ccg} ) > %{target} 2>&1

#########################################################
############# Train & Evaluate #################
#########################################################

[results/starSEM_2020/TE/%{parser}/%{t}_%{e}/%{proving_flags}_%{abduction_flags}.log]
cond = %{ parser in ('ccg', 'eccg', 'reccg', 'occg') or 'depccg' in parser }
# parse flags acronyms
ppars = %{ flags2pars(proving_flags) }
apars = %{ flags2pars(abduction_flags) }
train = %{ get_part(t) }
eval = %{ get_part(e) }
# create ccg_sen/*_sen.pl files
ccg_sen = %{ 'results/starSEM_2020/ccg_sen' if 'depccg' in parser else 'ccg_sen_d' }
dep.train_sen = %{ccg_sen}/SICK_%{train}_sen.pl
dep.eval_sen =  %{ccg_sen}/SICK_%{eval}_sen.pl
dep.train_ccg = %{ccg_sen}/SICK_%{train}_%{parser}.pl
dep.eval_ccg =  %{ccg_sen}/SICK_%{eval}_%{parser}.pl
dep.wn = WNProlog/wn.pl
ans = %{ target[:-3] + 'ans' }
recipe =
    mkdir -p results/starSEM_2020/TE/%{parser}/%{t}_%{e}
    ( time swipl -g "parList([allInt, waif('%{ans}'), complete_tree, %{ppars}]),  train_dev_eval_sick_parts(('%{train_ccg}','%{train_sen}'), _Ignore_Dev, ('%{eval_ccg}','%{eval_sen}'), [%{apars}])" -t halt -f prolog/main.pl  %{wn} ) > %{target} 2>&1

#########################################################
############# Train, Develop & Evaluate #################
#########################################################

[results/starSEM_2020/TDE/%{parser}/%{proving_flags}_%{abduction_flags}.log]
cond = %{ parser in ('ccg', 'eccg', 'reccg', 'occg') or 'depccg' in parser }
# parse flags acronyms
ppars = %{ flags2pars(proving_flags) }
apars = %{ flags2pars(abduction_flags) }
# create ccg_sen/*_sen.pl files
ccg_sen = %{ 'results/starSEM_2020/ccg_sen' if 'depccg' in parser else 'ccg_sen_d' }
dep.train_sen = %{ccg_sen}/SICK_train_sen.pl
dep.trial_sen = %{ccg_sen}/SICK_trial_sen.pl
dep.test_sen =  %{ccg_sen}/SICK_test_annotated_sen.pl
dep.train_ccg = %{ccg_sen}/SICK_train_%{parser}.pl
dep.trial_ccg = %{ccg_sen}/SICK_trial_%{parser}.pl
dep.test_ccg =  %{ccg_sen}/SICK_test_annotated_%{parser}.pl
dep.wn = WNProlog/wn.pl
ans = %{ target[:-3] + 'ans' }
recipe =
    mkdir -p results/starSEM_2020/TDE/%{parser}
    ( time swipl -g "parList([allInt, waif('%{ans}'), complete_tree, %{ppars}]),  train_dev_eval_sick_parts(('%{train_ccg}','%{train_sen}'), ('%{trial_ccg}', '%{trial_sen}'), ('%{test_ccg}','%{test_sen}'), [%{apars}])" -t halt -f prolog/main.pl %{wn} ) > %{target} 2>&1

#########################################################
############### N-fold Cross Validation #################
#########################################################

[results/%{task}/CV-%{n}/%{parser}/%{part}/%{proving_flags}_%{abduction_flags}.log]
cond = %{ (parser in ('ccg', 'eccg', 'reccg', 'occg') or 'depccg' in parser) and task in ('starSEM_2020', 'abduction') }
# parse flags acronyms
ppars = %{ flags2pars(proving_flags) }
apars = %{ flags2pars(abduction_flags) }
# create ccg_sen/*_sen.pl files
ccg_sen = %{ 'results/{}/ccg_sen'.format(task) if 'depccg' in parser else 'ccg_sen_d' }
dep.sen = %{ccg_sen}/SICK_%{part}_sen.pl
dep.ccg = %{ccg_sen}/SICK_%{part}_%{parser}.pl
dep.wn = WNProlog/wn.pl
recipe =
    mkdir -p results/%{task}/CV-%{n}/%{parser}/%{part}
    ( time swipl -g "parList([allInt, complete_tree, %{ppars}]), load_ccg_sen_probs('%{ccg}', '%{sen}', _TPIDA), cv_induce_knowledge(_PrIDs, _Answers, [fold-%{n}, %{apars}])" -t halt -f prolog/main.pl  %{wn} ) > %{target} 2>&1

# parList([aall, allInt, complete_tree, constchk, wn_ant, wn_sim, wn_der, no_kb, ral(100)]).


#########################################################
############### Experiments in the paper ################
#########################################################
# Cross validation with train & trial
[paper_cv3_cr%{c}_rm%{m}_re%{e}]
dep.cv3_tt_rMAX = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{m},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log
dep.cv3_tt_rEFF = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log

# ablation for cv and rEfficient
[paper_cv3_abl_cr%{c}_re%{e}]
type = task
dep.cv3_tt_rEFF_senConstChk = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},w3,-k,c%{c}_ab,cKB,cT,p123.log
dep.cv3_tt_rEFF_compTerms = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cKB,p123.log
dep.cv3_tt_rEFF_conWithKB = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cT,p123.log
dep.cv3_tt_rEFF_noWN = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},-k,-w,c%{c}_ab,ch,cKB,cT,p123.log
dep.cv3_tt_rEFF_useHKB = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},w3,c%{c}_ab,ch,cKB,cT,p123.log
dep.cv3_tt_rEFF_p12 = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cKB,cT,p12.log
dep.cv3_tt_rEFF_p1 = results/starSEM_2020/CV-3/ccg/train_trial/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cKB,cT,p1.log
#
# train & evaluation using 3 parsers for hybrid MAX rules
[paper_te_cr%{c}_rm%{m}]
type = task
dep.te_tt_rMAX_ccg = results/starSEM_2020/TE/ccg/TD_E/al,ch,r%{m},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log
dep.te_tt_rMAX_eccg = results/starSEM_2020/TE/eccg/TD_E/al,ch,r%{m},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log
dep.te_tt_rMAX_depccg = results/starSEM_2020/TE/depccg.trihf.sep/TD_E/al,ch,r%{m},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log
#
# train & evaluation using 3 parsers for hybrid EFF rules
[paper_te_cr%{c}_re%{e}]
type = task
dep.te_tt_rEFF_ccg = results/starSEM_2020/TE/ccg/TD_E/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log
dep.te_tt_rEFF_eccg = results/starSEM_2020/TE/eccg/TD_E/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log
dep.te_tt_rEFF_depccg = results/starSEM_2020/TE/depccg.trihf.sep/TD_E/al,ch,r%{e},w3,-k,c%{c}_ab,ch,cKB,cT,p123.log
#
# Run all experiments
[paper_cr%{c}_rm%{m}_re%{e}]
type = task
dep.cv3 = paper_cv3_cr%{c}_rm%{m}_re%{e}
dep.cv3_abl = paper_cv3_abl_cr%{c}_re%{e}
dep.te_max = paper_te_cr%{c}_rm%{m}
dep.te_eff = paper_te_cr%{c}_re%{e}
