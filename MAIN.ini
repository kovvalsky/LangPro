######################## Functions #####################
[]
prelude =
    import re, os, sys
    from os import path as op
    sys.path.append('./python')
    from produce_utils import *
    from itertools import product

    CC_BIN = '/media/kowalsky/Data/NLProc/parsers/rebank_candc/rebank_dist/bin'
    CC_BIN32 = '/media/kowalsky/Data/NLProc/parsers/rebank_candc/rebank_dist32/bin'
    CC_MODELS = '/media/kowalsky/Data/NLProc/parsers/rebank_candc/models'
    CC_2007 = '/media/kowalsky/Data/NLProc/parsers/candc-1.0'
    CC_2016 = '/media/kowalsky/Data/NLProc/parsers/candc-2.0'
    RECC_SUPER = '/media/kowalsky/Data/NLProc/parsers/rebank_candc/super'
    RECC_PARSER = '/media/kowalsky/Data/NLProc/parsers/rebank_candc/model_hybrid'
    EASYCCG = '/media/kowalsky/Data/NLProc/parsers/easyccg'
    EASYCCG_MODELS = '/media/kowalsky/Data/NLProc/parsers/models_easyccg'
    DEPCCG_MODELS = '/media/kowalsky/Data/NLProc/parsers/models_depccg'

    SICK_DIR = 'myNT/SICK_data'


###################################################
# Sentence Tokenization and NLI Prolog Convertion
###################################################

[%{path}/SICK_%{tok}]
type = task
cond = %{ tok in ('spacy', 'nltk', 'raw', 'own') }
deps = %{path}/SICK_sen.pl %{path}/SICK_%{tok}.spl %{path}/SICK_%{tok}.off.json

## _sen.pl file containing NLI problems in prolog format for display purposes
[%{path}/SICK_sen.pl]
dep.trial = SICK_dataset/SICK_trial.txt
dep.train = SICK_dataset/SICK_train.txt
dep.test = SICK_dataset/SICK_test_annotated.txt
recipe =
    mkdir -p %{path}
    python3 python/nlidata2prolog.py  --files trial %{trial} train %{train} test %{test} \
        --output %{path}/SICK --ext sen.pl --corpus sick_semeval
    sed -i -r "s/'([0-9]+)'/\1/" %{target}

## _{nltk,spacy}.pl file containing tokenized NLI problem sentences
# nltk is more conventional as compunds with a hyphen are a singel token
# 'own' is available for the datasets with its own tokenization
[%{path}/SICK_%{tok}.spl]
cond = %{ tok in ('spacy', 'nltk', 'raw', 'own') }
dep.trial = SICK_dataset/SICK_trial.txt
dep.train = SICK_dataset/SICK_train.txt
dep.test = SICK_dataset/SICK_test_annotated.txt
recipe =
    mkdir -p %{path}
    python3 python/nlidata2prolog.py  --files trial %{trial} train %{train} test %{test} \
        --output %{path}/SICK_%{tok} --ext spl off.json --corpus sick_semeval --tokenize %{tok}

[%{path}/SICK_%{tok}.off.json]
deps = %{path}/SICK_%{tok}.spl

###################################################
############ Lexical Annotations ##################
###################################################
# json files needs to be produced separately, not as part of other rules,
# because it takes time to create them and this avoid their accidental creation

###########################
# SpaCy annotationsof pos & lemma
# nltk_spacy_lg.json, spacy_spacy_trf.json
[%{path}/anno/%{tok}_spacy.%{size}_LemPos.json]
cond = %{ size in ('sm', 'md', 'lg', 'trf') and tok in ('spacy', 'nltk', 'own') }
input_flag = %{ '--raw' if tok == 'spacy' else '--tok' }
SICK_spl = %{ 'SICK_raw' if tok == 'spacy' else f"SICK_{tok}" }.spl
dep.spl = %{path}/%{SICK_spl}
recipe =
    mkdir -p %{path}/anno
    python3 python/lex_anno.py --spacy %{size} -l en %{input_flag} %{spl} --json %{target}

###########################
# Sense annotation with Amuse WSD api
[%{path}/anno/%{tok}_amuse_WN.json]
cond = %{ tok in ('spacy', 'nltk', 'own') }
input_flag = %{ '--raw' if tok == 'spacy' else '--tok' }
SICK_spl = %{ 'SICK_raw' if tok == 'spacy' else f"SICK_{tok}" }.spl
dep.spl = %{path}/SICK_raw.spl
recipe =
    mkdir -p %{path}/anno
    python3 python/lex_anno.py --amuse-wsd EN  %{input_flag} %{spl} --json %{target}

###########################
# EasyCCG lemmatization
[%{path}/anno/%{tok}_easyccg_Lem.json]
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.spl = %{path}/SICK_%{tok}.spl
dep.lem = %{path}/anno/%{tok}_easyccg.lem
recipe =
    mkdir -p %{path}/anno
    python3 python/apply_anno.py --tok-sen %{spl} --ann-sen %{lem} --ann-key l --sys easyccg --json %{target}

[%{path}/anno/%{tok}_easyccg.lem]
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.spl = %{path}/SICK_%{tok}.spl
dep.easyccg = %{EASYCCG}/easyccg.jar
recipe =
    mkdir -p %{path}/anno
    # for some lemmas are not lowercased, so they are lowercased with sed
    cat %{spl} | java -cp %{easyccg} uk.ac.ed.easyccg.lemmatizer.MorphaStemmer | sed -e 's/^\([A-Z]\)/\L\1/' > %{target}


###########################
# C&C tools v2016: Lemmas, POS tags, supertags, chunks & NER
# Getting lemma is possible from C&C, that's why no specific toosl for pos and ner are used
[%{path}/anno/%{tok}_cc2016.st_LemPosNE.json]
cond = %{ tok in ['nltk'] }
dep.ccg_pl = %{path}/anno/%{tok}_cc2016.st.prolog
sen_pl = ccg_sen_d/%{tok}_SICK_sen.pl
dep.spl = %{path}/SICK_%{tok}.spl
recipe =
    mkdir -p %{path}/anno
    python3 python/lex_anno_from_ccg.py --ccg %{ccg_pl}  --sys cc2016.st  --json %{target}

# [%{path}/anno/%{tok}_cc2016.st_LemPos.pipe]
# cond = %{ tok in ['nltk'] }
# dep.spl = %{path}/SICK_%{tok}.spl
# dep.models = %{CC_2016}/models/models
# dep.bin = %{CC_2016}/candc/bin/
# recipe =
#     mkdir -p %{path}/anno
#     %{bin}/pos --model %{models}/pos --input %{spl} | %{bin}/ner --model %{models}/ner --ifmt "%%w|%%p \n"

###########################
# rebanked C&C tools annotations
# It is much easier to extract lex annotations from CCG derivations
# This rule doesn't run the parser but uses ready ccg.pl file
# This is a workaround for failing to run rebanked ccg parser
# [%{path}/anno/%{tok}_recc.json]
# cond = %{ tok in ['nltk'] }
# reccg_pl = ccg_sen_d/%{tok}_SICK_ccg.pl
# sen_pl = ccg_sen_d/%{tok}_SICK_sen.pl
# dep.spl = %{path}/SICK_%{tok}.spl
# recipe =
#     mkdir -p %{path}/anno
#     python3 python/lex_anno_from_ccg.py --ccg %{reccg_pl} --nli %{sen_pl} --tok %{spl} --json %{target}

###########################
# Pos tagging with C&C
# [%{path}/anno/%{tok}_recc_Pos.json]
# cond = %{ tok in ('spacy', 'nltk', 'own') }
# dep.spl = %{path}/SICK_%{tok}.spl
# dep.pos = %{path}/anno/%{tok}_recc.pos
# recipe =
#     mkdir -p %{path}/anno
#     python3 python/apply_anno.py --tok-sen %{spl} --ann-sen %{pos} --ann-key ppos --json %{target}

# [%{path}/anno/%{tok}_recc.pos]
# cond = %{ tok in ('spacy', 'nltk', 'own') }
# dep.spl = %{path}/SICK_%{tok}.spl
# dep.pos = %{CC_BIN32}/pos
# dep.model = %{CC_MODELS}/pos
# recipe =
#     mkdir -p %{path}/anno
#     %{pos} --model %{model} --input %{spl} --ifmt "%%w \n" --ofmt "%%p \n" > %{target}

###################################################
############ Merge Lexical Annotations ############
###################################################
[%{path}/anno/%{tok}_anno_sen.pl]
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.anno_json = %{path}/anno/%{tok}_anno.json
recipe =
    swipl -f prolog/converter/anno_json2pl.pl  -g "anno_json2pl('%{anno_json}', '%{target}')" -t halt


[%{path}/anno/%{tok}_anno.json]
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.tok_off = %{path}/SICK_%{tok}.off.json
dep.amuse = %{path}/anno/%{tok}_amuse_WN.json
dep.cc2016_st = %{path}/anno/%{tok}_cc2016.st_LemPosNE.json
dep.easyccg_lem = %{path}/anno/%{tok}_easyccg_Lem.json
dep.spact_trf = %{path}/anno/%{tok}_spacy.trf_LemPos.json
recipe =
    python3 python/merge_anno.py  --shared-keys t  --json-ann %{tok_off} t! o!  --json-ann %{cc2016_st} l ppos ner  --json-ann %{easyccg_lem} l  --json-ann %{spact_trf} l ppos  --json-ann %{amuse} wn  --json %{target}

###################################################
################## CCG parsing ####################
###################################################

###########################
# ???
[%{path}/anno/%{tok}_cc.re.prolog]
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.spl = %{path}/SICK_not_%{tok}.spl
dep.bin = %{CC_BIN32}
dep.models = %{CC_MODELS}
dep.super = %{RECC_SUPER}
dep.parser = %{RECC_PARSER}
recipe =
    # using parsing to have access to lemmas
    mkdir -p %{path}/anno
    %{bin}/candc --models %{models} --candc-super %{super} --candc-parser %{parser} --candc-parser-noisy_rules=false --input %{spl} > %{target}


#########################################################
################# Parsing with C&C v2016 ################
# C&C parsing with standard model (1.02) for ccgbank
# This version supports boxer output and elimination of funny rules

[%{path}/anno/%{tok}_cc2016.st.pl]
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.pl = %{path}/anno/%{tok}_cc2016.st.prolog
dep.tok_off = %{path}/SICK_%{tok}.off.json
recipe =
    mkdir -p %{path}/anno
    # hacking prolog script in python, TODO this in prolog?
    python3 python/modify_ccg_pl.py --ccg %{pl} --sys 'cc2016.st' --anno-json %{tok_off} --anno-ord 1 2 o --out %{target}

[%{path}/anno/%{tok}_cc2016.st.prolog]
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.spl = %{path}/SICK_%{tok}.spl
dep.models = %{CC_2016}/models/models
dep.candc = %{CC_2016}/candc/bin/candc
recipe =
    mkdir -p %{path}/anno
    %{candc} --models %{models} --candc-parser-noisy_rules=false --input %{spl} --candc-printer boxer --output %{target}
#########################################################

#########################################################
################# Parsing with DepCCG ###################

[%{path}/anno/%{tok}_depccg.%{m}.%{g}.pl]
cond = %{ m in ('trihf') and g in ('sep', 'all') and tok in ('spacy', 'nltk', 'own') }
### convert depccg json derivations into prolog derivations
### derivation leaves contain cat, tok & tok_offset
dep.dep_json = %{path}/anno/%{tok}_depccg.%{m}.%{g}.json
dep.tok_off = %{path}/SICK_%{tok}.off.json
recipe =
    python3 python/depccg2prolog.py  %{dep_json} --tok-off %{tok_off}  >(sed -r 's/ccg\(([0-9]+)/ccg\(\1, depccg/' > %{target})

[%{path}/anno/%{tok}_depccg.%{m}.all.json]
### parsing sentences all together (surprisingly context of sentences matters)
cond = %{ m in ('trihf') and tok in ('spacy', 'nltk', 'own') }
dep.model = %{DEPCCG_MODELS}/tri_headfirst
dep.spl = %{path}/SICK_%{tok}.spl
recipe =
    cat %{spl} | depccg_en -m %{model} -f json > %{target}

[%{path}/anno/%{tok}_depccg.%{m}.sep.json]
### parsing sentences one by one
cond = %{ m in ('trihf') and tok in ('spacy', 'nltk', 'own') }
dep.model = %{DEPCCG_MODELS}/tri_headfirst
dep.spl = %{path}/SICK_%{tok}.spl
recipe =
    # while read line; do echo $line | depccg_en -m %{model} -f json; done < %{spl} > %{target} 2> %{target}.log
    python3 python/parse_with_depccg_en.py %{model} %{spl} --output %{target} --one
    # parses sentences by feeding them one-by-one to parser
#########################################################

#########################################################
################# Parsing with EasyCCG ##################

[%{path}/anno/%{tok}_easyccg.pl]
### convert easyccg's prolog format to langpro's one
dep.pl = %{path}/anno/%{tok}_easyccg.prolog
dep.tok_off = %{path}/SICK_%{tok}.off.json
recipe =
    swipl -f prolog/converter/prologCCG_to_boxerCCG.pl -l %{pl} -t halt -g "prolog_to_boxer('%{target}')"
    # hacking prolog script in python, TODO this in prolog?
    python3 python/modify_ccg_pl.py --ccg %{target} --sys easyccg --out %{target} --anno-json %{tok_off} --anno-ord 1 2 o --out %{target}


[%{path}/anno/%{tok}_easyccg.prolog]
### Before parsing, append each token with dummy annotations needed for prolog format output
cond = %{ tok in ('spacy', 'nltk', 'own') }
dep.spl = %{path}/SICK_%{tok}.spl
dep.tok_off = %{path}/SICK_%{tok}.off.json
dep.easyccg = %{EASYCCG}/easyccg.jar
dep.model = %{EASYCCG_MODELS}/standard
recipe =
    cat %{spl} | sed -r 's/([^ ]+)/\1|X|X/g' | java -jar %{easyccg} --model %{model} -i POSandNERtagged -o prolog | python3 python/prolog_easy2boxer.py > %{target}
############################################################




#############################################################
######################   LaTeX / PDF   ######################
#############################################################

#################################################
# LaTeX file with Trees for a particular sentence
[%{path}/latex/s%{sid}_%{anno_sys}.tex]
cond = %{ sid.isdigit() }
annos = flags2annos(anno_sys)
anno_sen = %{path}/anno/nltk_anno_sen.pl
parsed = %{path}/anno/nltk_%{abbr2model(der)}.pl
sen = %{path}/SICK_sen.pl
wn = WNProlog/wn.pl
recipe =
    mkdir -p %{path}/latex
    swipl -g "parList([ ccg(['%{abbr2tool(der)}']),  parts([train,trial,test]), anno_sys([%{annos}]) ]), latex_senIDs_trees([%{sid}], '%{target}'), halt" -f prolog/main.pl -l %{sen} %{anno_sen} %{parsed} %{wn}

# LaTeX file with Trees for a particular sentence
# Use all ccg parsers and annotations
[%{path}/latex/s%{sid}.tex]
cond = %{ sid.isdigit() }
anno = %{path}/anno/nltk_anno_sen.pl
all_parses = %{path}/anno/nltk_cc2016.st.pl %{path}/anno/nltk_easyccg.pl %{path}/anno/nltk_depccg.trihf.sep.pl
sen = %{path}/SICK_sen.pl
# wn = WNProlog/wn.pl
recipe =
    mkdir -p %{path}/latex
    swipl -g "latex_senID_all_ders(%{sid}, '%{target}'), halt" -f prolog/main.pl -l %{sen} %{anno} %{all_parses}

#################################################
# LaTeX file with Trees for a particular problem
[%{path}/latex/p%{sid}_%{norm}_%{der}.%{lem}.%{pos}.%{ner}.tex]
cond = %{ sid.isdigit() }
anno = %{path}/anno/nltk_anno_sen.pl
parsed = %{path}/anno/nltk_%{abbr2model(der)}.pl
normalize = %{ f"{flag2par(norm)}," if flag2par(norm) else '' }
sen = %{path}/SICK_sen.pl
wn = WNProlog/wn.pl
recipe =
    mkdir -p %{path}/latex
    swipl -g "parList([ %{normalize} ccg(['%{abbr2tool(der)}']),  parts([train,trial,test]), anno_sys([ccg-'%{abbr2tool(der)}', l-'%{abbr2tool(lem)}', ppos-'%{abbr2tool(pos)}', ner-'%{abbr2tool(ner)}']) ]), latex_probIDs_trees([%{sid}], '%{target}'), halt" -f prolog/main.pl -l %{sen} %{anno} %{parsed} %{wn}

#################################################
# generating pdf from tex
[%{path}.pdf]
dep.tex = %{path}.tex
# lualatex is for large files while pdflatex is better for files with non-asci symbols e.g.SICKNL-1964
latex = %{ 'pdflatex' if op.basename(path)[0].isdigit() else 'hash_extra=5000000 max_strings=5000000 lualatex' }
recipe =
    %{latex} --output-directory=%{op.dirname(path)} %{tex} > %{path}.log
    rm %{path}.{log,aux,tex}

# generating pdf from tex and vieweing
# myNT/SICK_data/latex/p7314_D.E.C.C.view
[%{path}.view]
cond = %{ 's_of_p' not in path }
type = task
dep.pdf = %{path}.pdf
recipe = atril %{pdf} & disown

# view pdfs of sentecne annotations of a problem (only ccg and anno view)
### myNT/SICK_data/latex/s_of_p7314.view
[%{path}/latex/s_of_p%{pid}.view]
type = task
cond = %{ pid.isdigit() }
sen_pl = %{path}/SICK_sen.pl
deps = %{ f"{path}/latex/s{sid}.view" for sid in pid2sids(sen_pl, pid) }
recipe =
    echo %{deps}

#############################################################
###################### Prove Specific #######################
#############################################################

# prove particular problems with a specific annotation pipeline
### myNT/SICK_data/prove_254.5085.5753.6205.8317_common.r200_D.S.S.C
[%{path}/%{prove}_%{pids}_%{config}_%{anno_sys}]
cond = %{ '?' not in anno_sys and prove in ('gprove','prove','gaprove') }
type = task
annos = %{flags2annos(anno_sys)}
params = %{flags2pars(config)}
main = prolog/main.pl
wn = WNProlog/wn.pl
sen = %{path}/SICK_sen.pl
anno_sen = %{path}/anno/nltk_anno_sen.pl
parsed = %{path}/anno/nltk_%{flags2ccgfile(anno_sys)}.pl
recipe =
    swipl -g "parList([ parts([train,trial]), %{params}, anno_sys([%{annos}]) ]), %{prove_type(prove,pids)}, halt" -f %{main} -l %{anno_sen} %{sen} %{parsed} %{wn}
# swipl -g "parList([ parts([train,trial]), aall, allInt, constchk, wn, llf_norm, ccg_norm, ral(200), anno_sys([ccg-'depccg', l-'spacy', ppos-'spacy', ner-'cc2016.st']) ]), entail_some([254]), halt" -f prolog/main.pl -l myNT/SICK_data/anno/nltk_anno_sen.pl myNT/SICK_data/SICK_sen.pl myNT/SICK_data/anno/nltk_depccg.trihf.sep.pl WNProlog/wn.pl

# underspecified version for anno_sys
### myNT/SICK_data/prove_254.5085.5753.6205.8317_common.r200_?.?.?.?
[%{path}/prove_%{pids}_%{config}_%{anno_sys}]
type = task
cond = %{'?' in anno_sys}
deps = %{ ' '.join([ f"{path}/prove_{pids}_{config}_{i}.log" for i in unfold_anno_inits(anno_sys) ]) }


# prove specific problems with specific annotations while using initial KB
### myNT/SICK_data/prove_iKB_6092.6096_common_D.S.S.C_disj\(bird,birdcage\)
[%{path}/prove_iKB_%{pids}_%{prove_config}_%{anno_sys}_%{KB}]
type = task
main = prolog/main.pl
wn = WNProlog/wn.pl
sen = %{path}/SICK_sen.pl
anno_sen = %{path}/anno/nltk_anno_sen.pl
parsed = %{path}/anno/nltk_%{flags2ccgfile(anno_sys)}.pl
#kb = %{flags2pars(abd_config)}
annos = %{flags2annos(anno_sys)}
params = %{flags2pars(prove_config)}
pid_lab = %{ pids_labs(sen, pids) }
recipe =
    swipl -g "parList([ parts([train,trial]), %{params}, anno_sys([%{annos}]) ]), predict_with_iKB([constchk,align-both], [%{KB}], [%{pid_lab}], Scores, Acc, Solved, Failed), format('Scores = ~w\nAcc = ~w\nSolved = ~w\nFailed = ~w\n', [Scores, Acc, Solved, Failed]), halt" -f %{main} -l %{anno_sen} %{sen} %{parsed} %{wn}

# maplist(add_lex_to_id_ans, [3400-no,1294-no], TrainIDAL), predict_with_iKB([constchk,align-both], KB, TrainIDAL, _, _Acc, SolvA0, FailA0).


#############################################################
######################   Evaluation   #######################
#############################################################
# prove with a single version of LP
### myNT/SICK_data/eval/T/50/common.c8_D.C.C.C.log
[%{path}/eval/%{p}/%{r_i}/%{config}_%{anno_sys}.log]
annos = %{flags2annos(anno_sys)}
params = %{flags2pars(config)}
part = %{get_part(p)}
rule_num = %{r_i2r(r_i)}
main = prolog/main.pl
wn = WNProlog/wn.pl
# SICK dir is fixed here != path
sen = %{SICK_DIR}/SICK_sen.pl
anno_sen = %{SICK_DIR}/anno/nltk_anno_sen.pl
parsed = %{SICK_DIR}/anno/nltk_%{flags2ccgfile(anno_sys)}.pl
recipe =
    mkdir -p %{path}/eval/%{p}/%{r_i}
    ( time swipl -g "parList([ pr_cmd, parts([%{part}]), ral(%{rule_num}), %{params}, anno_sys([%{annos}]) ]), entail_all, halt" -f %{main} -l %{anno_sen} %{sen} %{parsed} %{wn} ) > %{target} 2>&1
    sleep 5

# prove with a particular ccg parser fixed. It is created to save CPU times
### myNT/SICK_data/eval/T/50/common.c8_D.ans
[%{path}/eval/%{p}/%{r_i}/%{config}_%{anno_sys}]
type = task
dir = %{path}/eval/%{p}/%{r_i}
deps = %{ ' '.join([ f"{dir}/{config}_{i}.log" for i in unfold_anno_inits(anno_sys) ]) }

# prove with LPs with all possible annotation layer combinations (in total 18)
# and compute hybrid accuracy
### myNT/SICK_data/eval/T/hyb_r50.c8.ans
[%{path}/eval/%{p}/hyb_r%{r_i}.c%{c}.ans]
dir = %{path}/eval/%{p}/%{r_i}
deps = %{ ' '.join([ f"{dir}/common.c{c}_{i}.log" for i in  unfold_anno_inits("?.?.?.?") ]) }
recipe =
    mkdir -p %{dir}
    python3 python/evaluate.py --sys %{deps} --gld %{SICK_DIR}/SICK_sen.pl --hybrid --write-hybrid %{path}/eval/%{p}/hyb_r%{r_i}.c%{c}.ans

#########################################################
############### N-fold CV for Abduction #################
#########################################################

# myNT/SICK_data/cv-3/TD/50/common.c0_ab.ch.cKB.cT.p123_D.S.S.C.log
[%{path}/cv-%{n}/%{parts}/%{r_i}/%{prove_config}_%{abd_config}_%{anno_sys}.log]
cond = %{ n.isdigit() }
# expand configurations
rule_num = %{r_i2r(r_i)}
prove_param = %{flags2pars(prove_config)}
abduction_param = %{ flags2pars(abd_config) }
annos = %{flags2annos(anno_sys)}
ps = %{get_part(parts)}
# create ccg_sen/*_sen.pl files
main = prolog/main.pl
wn = WNProlog/wn.pl
sen = %{SICK_DIR}/SICK_sen.pl
anno_sen = %{SICK_DIR}/anno/nltk_anno_sen.pl
parsed = %{SICK_DIR}/anno/nltk_%{flags2ccgfile(anno_sys)}.pl
recipe =
    mkdir -p %{path}/cv-%{n}/%{parts}/%{r_i}
    ( time swipl -g "parList([pr_cmd, parts([%{ps}]), ral(%{rule_num}), complete_tree, %{prove_param}, anno_sys([%{annos}])]), cv_induce_knowledge(_PrIDs, _Answers, [fold-%{n}, %{abduction_param}]), halt" -f %{main} %{wn} %{anno_sen} %{parsed} %{sen} ) > %{target} 2>&1

#########################################################
############### Abduction for specific ##################
#########################################################

### myNT/SICK_data/abduce_2972_common_abduce_D.S.S.C
[%{path}/abduce_%{pids}_%{prove_config}_%{abd_config}_%{anno_sys}]
type = task
anno_sen = %{SICK_DIR}/anno/nltk_anno_sen.pl
parsed = %{SICK_DIR}/anno/nltk_%{flags2ccgfile(anno_sys)}.pl
sen = %{SICK_DIR}/SICK_sen.pl
# expand configurations
prove_param = %{flags2pars(prove_config)}
abduction_param = %{ flags2pars(abd_config) }
annos = %{flags2annos(anno_sys)}
pid_lab = %{ pids_labs(sen, pids) }

recipe =
    swipl -g "parList([parts([train,trial]), complete_tree, %{prove_param}, anno_sys([%{annos}])]), train_with_abduction([%{abduction_param}], [%{pid_lab}], IndKB, Acc), halt" -f prolog/main.pl WNProlog/wn.pl %{anno_sen} %{parsed} %{sen}
### parList([parts([train,trial]), complete_tree, aall, allInt, constchk, wn, llf_norm, ccg_norm, anno_sys([ccg-'depccg', l-'spacy', ppos-'spacy', ner-'cc2016.st'])]), train_with_abduction([align-both, constchk, constKB, compTerms, patterns-([_,_@_,(_@_)@_, _@(_@_)])], [2972-no], IndKB, Acc), halt" -f prolog/main.pl WNProlog/wn.pl myNT/SICK_data/anno/nltk_anno_sen.pl myNT/SICK_data/anno/nltk_depccg.trihf.sep.pl myNT/SICK_data/SICK_sen.pl

#########################################################
############### Abduction & Evaluation ##################
#########################################################

### myNT/SICK_data/abd_eval/TD_E/50birdcage_1/common.c0_abduce_D.S.S.C.log
[%{path}/abd_eval/%{train_parts}_%{eval_parts}/%{r_i}/%{prove_config}_%{abd_config}_%{anno_sys}.log]
cond = %{ set(train_parts) | set(eval_parts) <= set("TED")  }
# expand configurations
rule_num = %{r_i2r(r_i)}
prove_param = %{flags2pars(prove_config)}
abduction_param = %{ flags2pars(abd_config) }
annos = %{flags2annos(anno_sys)}
train = %{get_part(train_parts)}
test = %{get_part(eval_parts)}
parts = %{ f"{train},{test}" }
ans = %{ target[:-3] + 'ans' }
# create ccg_sen/*_sen.pl files
main = prolog/main.pl
wn = WNProlog/wn.pl
sen = %{SICK_DIR}/SICK_sen.pl
anno_sen = %{SICK_DIR}/anno/nltk_anno_sen.pl
parsed = %{SICK_DIR}/anno/nltk_%{flags2ccgfile(anno_sys)}.pl
recipe =
    mkdir -p %{path}/abd_eval/%{train_parts}_%{eval_parts}/%{r_i}
    ( time swipl -g "parList([pr_cmd, waif('%{ans}'), parts([%{parts}]), ral(%{rule_num}), complete_tree, %{prove_param}, anno_sys([%{annos}])]), train_eval_sick_parts([%{train}], [%{test}], [%{abduction_param}]), halt" -f %{main} %{wn} %{anno_sen} %{parsed} %{sen} ) > %{target} 2>&1
